{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import data from csv\n",
    "df = pd.read_csv('dataset/Orig_Parkinson.csv')\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct min-max standardization\n",
    "col = df.columns\n",
    "features = col[4:]\n",
    "location = 4\n",
    "for feature in features:\n",
    "    normalized = []\n",
    "    for i in df[feature]:\n",
    "        normalized.append(math.log(i, 10))\n",
    "    normalized = minmax_scale(normalized)\n",
    "    df = df.drop(columns=feature)\n",
    "    df.insert(loc=location,column=feature,value=normalized)\n",
    "    location+=1\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = df.columns[4:]\n",
    "\n",
    "data = pd.DataFrame(columns=attr)    # dataset taking mean\n",
    "\n",
    "data_1 = pd.DataFrame(columns=attr)    # dataset taking first records\n",
    "\n",
    "data_2 = pd.DataFrame(columns=attr)    # dataset taking second records\n",
    "\n",
    "data_3 = pd.DataFrame(columns=attr)    # dataset taking third records\n",
    "\n",
    "\n",
    "status = df['Status'].tolist()\n",
    "gender = df['Gender'].tolist()\n",
    "new_status = []\n",
    "new_gender = []\n",
    "for i in range(0,len(status),3):\n",
    "    new_status.append(status[i])\n",
    "    new_gender.append(gender[i])\n",
    "    \n",
    "    mean = df[attr].iloc[[i,i+1,i+2]].mean(axis=0)\n",
    "    data = data.append(mean,ignore_index=True)\n",
    "    data_1 = data_1.append(df[attr].iloc[i],ignore_index=True)\n",
    "    data_2 = data_2.append(df[attr].iloc[i+1],ignore_index=True)\n",
    "    data_3 = data_3.append(df[attr].iloc[i+2],ignore_index=True)\n",
    "    \n",
    "data.insert(0,'Gender',new_gender)\n",
    "data.insert(0,'Status',new_status)\n",
    "data_1.insert(0,'Gender',new_gender)\n",
    "data_1.insert(0,'Status',new_status)\n",
    "data_2.insert(0,'Gender',new_gender)\n",
    "data_2.insert(0,'Status',new_status)\n",
    "data_3.insert(0,'Gender',new_gender)\n",
    "data_3.insert(0,'Status',new_status)\n",
    "\n",
    "#data_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find high correlation attributes \n",
    "features = data.columns[2:]\n",
    "for f1 in range(len(features)):\n",
    "    for f2 in range(f1+1,len(features)):\n",
    "        corr = data[features[f1]].corr(data[features[f2]])\n",
    "        if corr>=0.9:\n",
    "            print(features[f1] + \", \"+ features[f2]+ \": \"+str(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct dimension reduction on average data\n",
    "data_reduced_all = data.drop(columns = [\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\",\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\n",
    "                                        \"Shim_APQ11\",\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\"])\n",
    "data_reduced_Jitter = data.drop(columns = [\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\"])\n",
    "data_reduced_Shim = data.drop(columns = [\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\"Shim_APQ11\"])\n",
    "data_reduced_HNR = data.drop(columns = [\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\"])\n",
    "\n",
    "# conduct dimension reduction on 1st result data\n",
    "data_1_reduced_all = data_1.drop(columns = [\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\",\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\n",
    "                                        \"Shim_APQ11\",\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\"])\n",
    "data_1_reduced_Jitter = data_1.drop(columns = [\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\"])\n",
    "data_1_reduced_Shim = data_1.drop(columns = [\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\"Shim_APQ11\"])\n",
    "data_1_reduced_HNR = data_1.drop(columns = [\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\"])\n",
    "\n",
    "# conduct dimension reduction on 2nd result data\n",
    "data_2_reduced_all = data_2.drop(columns = [\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\",\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\n",
    "                                        \"Shim_APQ11\",\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\"])\n",
    "data_2_reduced_Jitter = data_2.drop(columns = [\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\"])\n",
    "data_2_reduced_Shim = data_2.drop(columns = [\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\"Shim_APQ11\"])\n",
    "data_2_reduced_HNR = data_2.drop(columns = [\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\"])\n",
    "\n",
    "\n",
    "# conduct dimension reduction on 3rd result data\n",
    "data_3_reduced_all = data_3.drop(columns = [\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\",\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\n",
    "                                        \"Shim_APQ11\",\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\"])\n",
    "data_3_reduced_Jitter = data_3.drop(columns = [\"Jitter_abs\",\"Jitter_RAP\",\"Jitter_PPQ\"])\n",
    "data_3_reduced_Shim = data_3.drop(columns = [\"Shim_dB\",\"Shim_APQ3\",\"Shim_APQ5\",\"Shim_APQ11\"])\n",
    "data_3_reduced_HNR = data_3.drop(columns = [\"HNR15\",\"HNR25\",\"HNR35\",\"HNR38\"])\n",
    "\n",
    "#data_reduced_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## attribute descriptive stat info of control individuals and PD individuals\n",
    "control = data.iloc[:40, :].drop('Status', axis = 1).drop('Gender',axis = 1)  # health people\n",
    "pak = data.iloc[40:, :].drop('Status', axis = 1).drop('Gender',axis = 1)   # Parkinson people\n",
    "\n",
    "print(control.describe())\n",
    "print(pak.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('dataset/averaged.csv') # data taking all 3 result average of each person\n",
    "\n",
    "data_1.to_csv('dataset/record1.csv') # data taking only first result of each person\n",
    "data_2.to_csv('dataset/record2.csv') # data taking only second result of each person\n",
    "data_3.to_csv('dataset/record3.csv') # data taking only third result of each person\n",
    "\n",
    "data_reduced_all.to_csv('dataset/reduced.csv') # data with dimension reduction on average data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
